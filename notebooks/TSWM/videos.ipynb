{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[COMPLETED]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re, os \n",
    "import cv2\n",
    "from pytube import YouTube\n",
    "# pytubeはよく壊れるので,壊れてたらgithubのissueを確認する\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"[COMPLETED]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[COMPLETED2]\n"
     ]
    }
   ],
   "source": [
    "def scrape_videos(query, path, n):\n",
    "    url ='https://www.youtube.com/results?search_query='+query\n",
    "    r = requests.get(url)\n",
    "    page = r.text\n",
    "    soup=bs(page,'html.parser')\n",
    "    res=soup.find_all('a',{'href': re.compile(r'watch')})\n",
    "    i = 0\n",
    "    for l in res:\n",
    "        link = \"https://www.youtube.com\"+l.get(\"href\")\n",
    "        myVideo = YouTube(link)\n",
    "        print(link)\n",
    "        myVideo.streams.first().download(output_path=path, filename='ヒカキン')\n",
    "        i += 1 \n",
    "        #print(\"[INFO] Downloaded {0} for {1}\".format(myVideo,title, query))\n",
    "        print(\"[COMPLETED3]Downloaded\")\n",
    "        if i >= n:\n",
    "            break\n",
    "            \n",
    "def tsne(x, n):\n",
    "    X_embedded = TSNE(n_components=n).fit_transform(x)\n",
    "    return X_embedded\n",
    "\n",
    "print(\"[COMPLETED2]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cut videos into scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.youtube.com/watch?v=m5oMWgiN9zY\n",
      "[COMPLETED3]Downloaded\n",
      "[INFO] Starting scene detection on みなさんにお願いがあります。.mp4\n",
      "[INFO] Starting scene detection on 【YouTuber必見】歯医者でも動画編集できる方法を発明しました。.mp4\n",
      "[INFO] Starting scene detection on ヒカキン.mp4\n",
      "[COMPLETED] FINISHED Downloading Videos for はじめしゃちょー\n"
     ]
    }
   ],
   "source": [
    "import subprocess as sp\n",
    "\n",
    "name_list = open(\"pyFiles/name_list.txt\", \"r\").read().splitlines()\n",
    "for line in name_list:\n",
    "    name, yt_url = line.split(\" \")\n",
    "    path = \"./data/videos/{0}/\".format(name)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    scrape_videos(name, path, 0)\n",
    "    \n",
    "    video_list = os.listdir(\"./data/videos/{0}/\".format(name))\n",
    "    for fname in video_list:\n",
    "        print(\"[INFO] Starting scene detection on {0}\".format(fname))\n",
    "        \n",
    "        command = ([\n",
    "            \"scenedetect\",\n",
    "            \"-i\",\n",
    "            \"./data/videos/{0}/{1}\".format(name, fname),\n",
    "            \"-o\",\n",
    "            \"./data/videos/{0}/\".format(name),\n",
    "            \"detect-content\",\n",
    "            \"-t\",\n",
    "            \"27\",\n",
    "            \"split-video\",\n",
    "        ])\n",
    "        '''proc = sp.run(command, stdout=sp.PIPE, stderr=sp.PIPE)\n",
    "        if proc.returncode==0:\n",
    "            print(proc.stdout.decode(\"utf8\"))\n",
    "        else:\n",
    "            print(proc.stderr.decode(\"utf8\"))\n",
    "        os.remove(\"./data/videos/{0}/{1}\".format(name, fname))'''\n",
    "\n",
    "    print(\"[COMPLETED] FINISHED Downloading Videos for {0}\".format(name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cut roi's in each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK]\n",
      "[COMPLEATED READ]\n",
      "9715\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/average_landmarks.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-03bdcc6ac01d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mroi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgb_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'distance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#int付け加えた\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbox_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe_number\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mconf_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe_number\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-03bdcc6ac01d>\u001b[0m in \u001b[0;36mcheck_face\u001b[0;34m(img, name, method)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarp_face2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_encodings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-03bdcc6ac01d>\u001b[0m in \u001b[0;36mwarp_face2\u001b[0;34m(ROI, landmarks)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0maverage_landmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/average_landmarks.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     peripheral_points = [\n\u001b[1;32m     19\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/average_landmarks.npy'"
     ]
    }
   ],
   "source": [
    "#!pip install dlib\n",
    "#!pip install face_recognition\n",
    "#!pip install imutils\n",
    "#!pip install google_images_download\n",
    "#!pip install wheel\n",
    "#!pip install scikit-learn\n",
    "\n",
    "print(\"[OK]\")\n",
    "import dlib\n",
    "from pyFiles.create_image_dataset import *\n",
    "\n",
    "def warp_face2(ROI, landmarks):\n",
    "        # Output image\n",
    "    h = w = 224\n",
    "    img = np.zeros((h, w, 3), np.float32())\n",
    "\n",
    "    average_landmarks = np.load(\"./data/average_landmarks.npy\")\n",
    "    peripheral_points = [\n",
    "        [0, 0],\n",
    "        [0, w / 2],\n",
    "        [0, w - 1],\n",
    "        [h / 2, 0],\n",
    "        [h / 2, w - 1],\n",
    "        [h - 1, 0],\n",
    "        [h - 1, w / 2],\n",
    "        [h - 1, w - 1],\n",
    "    ]\n",
    "    landmarks = np.append(landmarks, peripheral_points, axis=0)\n",
    "\n",
    "\n",
    "    # Warp input images to average image landmarks\n",
    "    dt = Delaunay(average_landmarks).simplices\n",
    "\n",
    "    # Transform triangles one by ones\n",
    "    for j in range(0, len(dt)):\n",
    "        tin = []\n",
    "        tout = []\n",
    "\n",
    "        for k in range(0, 3):\n",
    "            pIn = landmarks[dt[j][k]]\n",
    "            pIn = constrainPoint(pIn, w, h)\n",
    "\n",
    "            pOut = average_landmarks[dt[j][k]]\n",
    "            pOut = constrainPoint(pOut, w, h)\n",
    "\n",
    "            tin.append(pIn)\n",
    "            tout.append(pOut)\n",
    "\n",
    "        warpTriangle(ROI, img, tin, tout)\n",
    "\n",
    "    return img.astype('uint8')\n",
    "    \n",
    "    print(\"[OK1]\")\n",
    "\n",
    "def check_face(img, name, method):\n",
    "    face_landmarks = face_recognition.face_landmarks(img, model='large')\n",
    "    tri_list, pt_list, delaunay_face = get_delaunay(face_landmarks, img)\n",
    "    ROI, landmarks = tilt_crop_scale(pt_list, img)\n",
    "    if len(ROI) == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        img = warp_face2(ROI[0], landmarks[0])\n",
    "        enc = face_recognition.face_encodings(img)\n",
    "    \n",
    "        if len(enc) == 0:\n",
    "            return -2\n",
    "    \n",
    "        elif method == 'OCSVM':\n",
    "            t = clf_dict[name].predict(enc)\n",
    "            return t\n",
    "        else:\n",
    "            return -3\n",
    "\n",
    "    #if method == 'distance':\n",
    "        #dist = np.linalg.norm(enc_ave[name] - enc)#enc_ave\n",
    "        #return dist\n",
    "\n",
    "weights = './data/mmod_human_face_detector.dat'\n",
    "face_detector = dlib.cnn_face_detection_model_v1(weights)\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "print(\"[COMPLEATED READ]\")\n",
    "\n",
    "name_list = open(\"./pyFiles/name_list.txt\", \"r\").read().splitlines()\n",
    "for line in name_list:\n",
    "    name, yt_url = line.split(\" \")\n",
    "    video_list = os.listdir(\"./data/videos/{0}/\".format(name))\n",
    "\n",
    "    for fname in video_list:\n",
    "        input_movie = cv2.VideoCapture(\"./data/videos/{0}/{1}\".format(name, fname))\n",
    "        length = int(input_movie.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        codec = int(input_movie.get(cv2.CAP_PROP_FOURCC))\n",
    "        fps = int(input_movie.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "        frame_width = int(input_movie.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(input_movie.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            \n",
    "        if not os.path.exists(\"./data/silent_vids/{0}\".format(name)):\n",
    "            os.makedirs(\"./data/silent_vids/{0}\".format(name))\n",
    "        writer = cv2.VideoWriter(\"./data/silent_vids/{0}/{1}\".format(name, fname),  cv2.VideoWriter_fourcc(*'XVID'), fps, (224,224))\n",
    "\n",
    "        frame_number=0\n",
    "        conf_list = [0.5]*(length+1)\n",
    "        box_list = [None]*(length+1)\n",
    "        frame_list = [None]*(length+1)\n",
    "        print(length)\n",
    "        while True:\n",
    "            # Grab a single frame of video\n",
    "            ret, frame = input_movie.read()\n",
    "            frame_number += 1\n",
    "\n",
    "            # Quit when the input video file ends\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "            rgb_frame = frame[:, :, ::-1]\n",
    "            frame_list[frame_number] = rgb_frame\n",
    "\n",
    "            # Find all the faces and face encodings in the current frame of video\n",
    "            faces, scores, _ = face_detector.run(rgb_frame, 1, -0.5)\n",
    "            for i, (face,score) in enumerate(zip(faces, scores)):\n",
    "                left = face.left()\n",
    "                top = face.top()\n",
    "                right = face.right()\n",
    "                bottom = face.bottom()\n",
    "                #print(i)\n",
    "                \n",
    "                roi = rgb_frame[top:bottom, left:right]\n",
    "                t = int(check_face(roi, name, 'distance'))#int付け加えた\n",
    "                if 0 < t and t < 0.5:\n",
    "                    if box_list[frame_number] == None or t < conf_list[frame_number]:\n",
    "                        conf_list[frame_number] = t\n",
    "                        box_list[frame_number] = face\n",
    "                    else:\n",
    "                        continue\n",
    "                print(t)\n",
    "                    \n",
    "        print(\"[OK]\")\n",
    "            \n",
    "        for i, box in enumerate(box_list):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            elif box == None:\n",
    "                box_list[i] = box_list[i - 1]\n",
    "                \n",
    "        for i, box in enumerate(box_list):\n",
    "            if box == None:\n",
    "                roi = np.zeros((224,224,3), np.uint8)\n",
    "                continue\n",
    "            else:\n",
    "                face = box_list[i] \n",
    "                rgb_frame = frame_list[i]\n",
    "                left = face.left()\n",
    "                top = face.top()\n",
    "                right = face.right()\n",
    "                bottom = face.bottom()\n",
    "                roi = rgb_frame[top:bottom, left:right]\n",
    "                roi = cv2.resize(roi, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)[:, :, ::-1]\n",
    "            writer.write(roi)\n",
    "        writer.release()    \n",
    "        \n",
    "        print(\"[ALL COMPLEATED]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
